"""
DI-2D Analysis API Endpoints
"""
from fastapi import APIRouter, UploadFile, File, Form, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
import logging
from typing import Optional, Dict, Any

from app.services.analyzer import analyzer
from app.services.werk24_analyzer import werk24_analyzer
from app.models.analysis import DrawingAnalysisResult, AnalysisRequest
from app.core.exceptions import AIKeyError, FileProcessingError, AnalysisError

logger = logging.getLogger(__name__)

router = APIRouter()

@router.post("/analyze", response_model=DrawingAnalysisResult)
async def analyze_drawing(
    file: UploadFile = File(..., description="2D teknik resim dosyasƒ± (PDF, PNG, JPG)"),
    model: str = Form("gpt-5.2", description="AI modeli"),
    max_tokens: int = Form(150000, description="Maksimum token"),
    reasoning_level: str = Form("high", description="D√º≈ü√ºnme seviyesi (medium|high|xhigh)"),
    enhance_mode: str = Form("balanced", description="G√∂r√ºnt√º iyile≈ütirme (fast|balanced|aggressive)")
):
    """
    2D teknik resim analizi
    
    **Desteklenen Formatlar:** PDF, PNG, JPG, JPEG
    
    **AI Modelleri:**
    - `werk24-professional` (Werk24) - **Profesyonel, en doƒüru** üèÜ
    - `gpt-5.2` (OpenAI) - **En geli≈ümi≈ü reasoning** ‚≠ê (Yeni - Aralƒ±k 2025)
    - `gpt-5.2-chat` (OpenAI) - Chat optimize edilmi≈ü versiyon
    - `gpt-4-vision-preview` (OpenAI) - Geri uyumluluk
    - `claude-3-5-sonnet-20241022` (Anthropic) - Hƒ±zlƒ± ve g√ºvenilir
    
    **Reasoning Level (GPT-5.2 i√ßin):**
    - `medium`: Orta seviye analiz (~2-3 dk)
    - `high`: Detaylƒ± analiz (~5-7 dk) - √ñnerilen ‚≠ê
    - `xhigh`: En derin analiz (~10-15 dk) - Karma≈üƒ±k resimler i√ßin
    
    **Enhance Mode:**
    - `fast`: Minimal i≈üleme
    - `balanced`: Dengeli iyile≈ütirme - √ñnerilen
    - `aggressive`: Maksimum keskinle≈ütirme
    """
    try:
        # Dosya kontrol√º
        if not file.filename:
            raise FileProcessingError("Dosya adƒ± bulunamadƒ±")
        
        # Uzantƒ± kontrol√º
        allowed_extensions = ['.pdf', '.png', '.jpg', '.jpeg']
        file_ext = file.filename.lower()[-4:]
        if not any(file_ext.endswith(ext) for ext in allowed_extensions):
            raise FileProcessingError(f"Desteklenmeyen dosya formatƒ±. ƒ∞zin verilenler: {', '.join(allowed_extensions)}")
        
        # Dosyayƒ± oku
        file_bytes = await file.read()
        
        if len(file_bytes) == 0:
            raise FileProcessingError("Bo≈ü dosya")
        
        if len(file_bytes) > 20 * 1024 * 1024:  # 20MB limit
            raise FileProcessingError("Dosya √ßok b√ºy√ºk (max 20MB)")
        
        logger.info(f"üìÑ Received file: {file.filename} ({len(file_bytes)} bytes)")
        
        # Model se√ßimine g√∂re analiz yap
        if model == "werk24-professional":
            # Werk24 ile analiz
            logger.info("üîß Using Werk24 Professional API")
            result = await werk24_analyzer.analyze(
                file_bytes=file_bytes,
                filename=file.filename,
                confidence_threshold=0.7
            )
        else:
            # Standart AI modelleri ile analiz
            result = await analyzer.analyze(
                file_bytes=file_bytes,
                filename=file.filename,
                model=model,
                max_tokens=max_tokens,
                reasoning_level=reasoning_level,
                enhance_mode=enhance_mode
            )
        
        return result
        
    except AIKeyError as e:
        logger.error(f"‚ùå AI Key Error: {e.detail}")
        raise HTTPException(status_code=401, detail=e.detail)
    except FileProcessingError as e:
        logger.error(f"‚ùå File Processing Error: {e.detail}")
        raise HTTPException(status_code=422, detail=e.detail)
    except AnalysisError as e:
        logger.error(f"‚ùå Analysis Error: {e.detail}")
        raise HTTPException(status_code=500, detail=e.detail)
    except Exception as e:
        logger.error(f"‚ùå Unexpected error: {e}")
        raise HTTPException(status_code=500, detail=f"Beklenmeyen hata: {str(e)}")


@router.get("/health")
async def health_check():
    """
    Servis saƒülƒ±k kontrol√º
    """
    return {
        "status": "healthy",
        "service": "DI-2D Analysis API",
        "version": "1.0.0",
        "models_available": {
            "openai": analyzer.openai_client is not None,
            "anthropic": analyzer.anthropic_client is not None
        }
    }


@router.get("/models")
async def list_models():
    """
    Desteklenen AI modellerini listele
    """
    models = []
    
    # Werk24 Professional (her zaman listede)
    models.append({
        "id": "werk24-professional",
        "name": "Werk24 Professional üèÜ",
        "provider": "Werk24",
        "description": "Profesyonel, en y√ºksek doƒüruluk - 100 deneme lisansƒ±",
        "recommended": True,
        "features": [
            "Y√ºksek doƒüruluklu boyut okuma",
            "GD&T tolerans analizi",
            "Malzeme tanƒ±ma",
            "Y√ºzey p√ºr√ºzl√ºl√ºƒü√º",
            "Di≈ü √∂zellikleri"
        ]
    })
    
    # GPT-5.2 (Aralƒ±k 2025 - Yeni!)
    if analyzer.openai_client:
        models.extend([
            {
                "id": "gpt-5.2",
                "name": "GPT-5.2 ‚≠ê (Yeni!)",
                "provider": "OpenAI",
                "description": "En geli≈ümi≈ü reasoning, derin analiz - Aralƒ±k 2025",
                "recommended": True,
                "features": [
                    "xHigh reasoning modu",
                    "Responses API",
                    "Chain-of-thought korunumu",
                    "√áok adƒ±mlƒ± muhakeme"
                ]
            },
            {
                "id": "gpt-5.2-chat",
                "name": "GPT-5.2 Chat",
                "provider": "OpenAI",
                "description": "Chat optimize edilmi≈ü versiyon",
                "recommended": False
            },
            {
                "id": "gpt-4-vision-preview",
                "name": "GPT-4 Vision (Legacy)",
                "provider": "OpenAI",
                "description": "Geri uyumluluk i√ßin",
                "recommended": False
            }
        ])
    
    if analyzer.anthropic_client:
        models.extend([
            {
                "id": "claude-3-5-sonnet-20241022",
                "name": "Claude 3.5 Sonnet",
                "provider": "Anthropic",
                "description": "Hƒ±zlƒ± ve g√ºvenilir analiz",
                "recommended": False
            }
        ])
    
    return {
        "models": models,
        "total": len(models)
    }


@router.post("/compare", response_model=Dict[str, Any])
async def compare_analysis(
    file: UploadFile = File(...),
    model1: str = Form("werk24-professional"),
    model2: str = Form("gpt-5.2"),
    reasoning_level: str = Form("medium"),
    background_tasks: BackgroundTasks = BackgroundTasks()
):
    """
    ƒ∞ki farklƒ± modelle aynƒ± teknik resmi analiz et ve sonu√ßlarƒ± kar≈üƒ±la≈ütƒ±r
    
    - **file**: Teknik resim dosyasƒ± (PDF, PNG, JPEG)
    - **model1**: ƒ∞lk model (varsayƒ±lan: werk24-professional)
    - **model2**: ƒ∞kinci model (varsayƒ±lan: gpt-5.2)
    - **reasoning_level**: GPT-5.2 i√ßin reasoning seviyesi (low/medium/high/xhigh)
    
    Returns:
        Kar≈üƒ±la≈ütƒ±rmalƒ± analiz sonu√ßlarƒ±
    """
    try:
        logger.info(f"Kar≈üƒ±la≈ütƒ±rmalƒ± analiz ba≈ülatƒ±ldƒ±: {model1} vs {model2}")
        
        # Dosya kontrol√º
        if not file.filename:
            raise FileProcessingError("Dosya adƒ± bulunamadƒ±")
        
        # Uzantƒ± kontrol√º
        allowed_extensions = ['.pdf', '.png', '.jpg', '.jpeg']
        file_ext = file.filename.lower()[-4:]
        if not any(file_ext.endswith(ext) for ext in allowed_extensions):
            raise FileProcessingError(f"Desteklenmeyen dosya formatƒ±. ƒ∞zin verilenler: {', '.join(allowed_extensions)}")
        
        # Dosyayƒ± oku
        file_bytes = await file.read()
        
        if len(file_bytes) == 0:
            raise FileProcessingError("Bo≈ü dosya")
        
        if len(file_bytes) > 20 * 1024 * 1024:  # 20MB limit
            raise FileProcessingError("Dosya √ßok b√ºy√ºk (max 20MB)")
        
        logger.info(f"üìÑ Received file: {file.filename} ({len(file_bytes)} bytes)")
        
        # Model 1 analizi
        logger.info(f"üîç Model 1 analizi ba≈ülƒ±yor: {model1}")
        if model1 == "werk24-professional":
            result1 = await werk24_analyzer.analyze(
                file_bytes=file_bytes,
                filename=file.filename,
                confidence_threshold=0.7
            )
        else:
            result1 = await analyzer.analyze(
                file_bytes=file_bytes,
                filename=file.filename,
                model=model1,
                reasoning_level=reasoning_level
            )
        
        # Pydantic model'i dict'e √ßevir
        result1_dict = result1.model_dump() if hasattr(result1, 'model_dump') else result1
        logger.info(f"‚úÖ Model 1 tamamlandƒ± ({result1_dict.get('metadata', {}).get('processing_time', 0):.2f}s)")
        
        # Model 2 analizi
        logger.info(f"üîç Model 2 analizi ba≈ülƒ±yor: {model2}")
        if model2 == "werk24-professional":
            result2 = await werk24_analyzer.analyze(
                file_bytes=file_bytes,
                filename=file.filename,
                confidence_threshold=0.7
            )
        else:
            result2 = await analyzer.analyze(
                file_bytes=file_bytes,
                filename=file.filename,
                model=model2,
                reasoning_level=reasoning_level
            )
        
        # Pydantic model'i dict'e √ßevir
        result2_dict = result2.model_dump() if hasattr(result2, 'model_dump') else result2
        logger.info(f"‚úÖ Model 2 tamamlandƒ± ({result2_dict.get('metadata', {}).get('processing_time', 0):.2f}s)")
        
        # Kar≈üƒ±la≈ütƒ±rma raporu olu≈ütur
        comparison = {
            "timestamp": result1_dict.get("metadata", {}).get("timestamp", ""),
            "model1": {
                "name": model1,
                "provider": result1_dict.get("metadata", {}).get("model_provider", ""),
                "processing_time": result1_dict.get("metadata", {}).get("processing_time", 0),
                "confidence": result1_dict.get("metadata", {}).get("confidence_score", 0),
                "result": result1_dict
            },
            "model2": {
                "name": model2,
                "provider": result2_dict.get("metadata", {}).get("model_provider", ""),
                "processing_time": result2_dict.get("metadata", {}).get("processing_time", 0),
                "confidence": result2_dict.get("metadata", {}).get("confidence_score", 0),
                "result": result2_dict
            },
            "comparison_notes": {
                "time_difference": abs(
                    result1_dict.get("metadata", {}).get("processing_time", 0) - 
                    result2_dict.get("metadata", {}).get("processing_time", 0)
                ),
                "confidence_difference": abs(
                    result1_dict.get("metadata", {}).get("confidence_score", 0) - 
                    result2_dict.get("metadata", {}).get("confidence_score", 0)
                ),
                "faster_model": model1 if result1_dict.get("metadata", {}).get("processing_time", 0) < result2_dict.get("metadata", {}).get("processing_time", 0) else model2,
                "higher_confidence": model1 if result1_dict.get("metadata", {}).get("confidence_score", 0) > result2_dict.get("metadata", {}).get("confidence_score", 0) else model2
            }
        }
        
        logger.info(f"Kar≈üƒ±la≈ütƒ±rma tamamlandƒ±: {comparison['comparison_notes']}")
        return comparison
        
    except AIKeyError as e:
        logger.error(f"‚ùå AI Key Error: {e.detail}")
        raise HTTPException(status_code=401, detail=e.detail)
    except FileProcessingError as e:
        logger.error(f"‚ùå File Processing Error: {e.detail}")
        raise HTTPException(status_code=422, detail=e.detail)
    except AnalysisError as e:
        logger.error(f"‚ùå Analysis Error: {e.detail}")
        raise HTTPException(status_code=500, detail=e.detail)
    except Exception as e:
        logger.error(f"‚ùå Unexpected error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Kar≈üƒ±la≈ütƒ±rma hatasƒ±: {str(e)}")
