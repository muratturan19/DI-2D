"""
DI-2D Geli≈ümi≈ü AI Analiz Servisi
√ñzellikle 2D teknik resim okuma i√ßin optimize edilmi≈ü

Desteklenen Modeller:
- GPT-5.2 (OpenAI) - En geli≈ümi≈ü reasoning, √∂nerilen
- GPT-4 Vision (OpenAI) - Geri uyumluluk
- Claude 3.5 Sonnet (Anthropic)
- Gemini 1.5 Pro (Google)

√ñzellikler:
- √áoklu model desteƒüi
- GPT-5.2 Responses API entegrasyonu
- Detaylƒ± boyut okuma
- Geometrik tolerans algƒ±lama
- Malzeme ve y√ºzey i≈ülemi tanƒ±ma
- ƒ∞malat √∂nerileri
"""
import os
import base64
import logging
from typing import Dict, Any, Optional
from openai import OpenAI
from anthropic import Anthropic
import json

from app.core.config import settings
from app.core.exceptions import AIKeyError, AnalysisError
from app.models.analysis import DrawingAnalysisResult, AnalysisMetadata
from .preprocessor import preprocess_drawing
from .prompts import get_analysis_prompt

logger = logging.getLogger(__name__)

class DrawingAnalyzer:
    """Teknik resim analiz servisi"""
    
    def __init__(self):
        """AI istemcilerini ba≈ülat"""
        # OpenAI
        if settings.openai_api_key:
            self.openai_client = OpenAI(api_key=settings.openai_api_key)
            logger.info("‚úÖ OpenAI client initialized")
        else:
            self.openai_client = None
            logger.warning("‚ö†Ô∏è OpenAI API key not found")
        
        # Anthropic
        if settings.anthropic_api_key:
            self.anthropic_client = Anthropic(api_key=settings.anthropic_api_key)
            logger.info("‚úÖ Anthropic client initialized")
        else:
            self.anthropic_client = None
            logger.warning("‚ö†Ô∏è Anthropic API key not found")
    
    async def analyze(
        self,
        file_bytes: bytes,
        filename: str,
        model: str = "gpt-4-vision-preview",
        max_tokens: int = 150000,
        reasoning_level: str = "high",
        enhance_mode: str = "balanced"
    ) -> DrawingAnalysisResult:
        """
        Teknik resmi analiz et
        
        Args:
            file_bytes: Dosya baytlarƒ±
            filename: Dosya adƒ±
            model: AI modeli
            max_tokens: Maksimum token sayƒ±sƒ±
            reasoning_level: D√º≈ü√ºnme seviyesi ("medium", "high", "xhigh")
            enhance_mode: G√∂r√ºnt√º iyile≈ütirme modu ("fast", "balanced", "aggressive")
        
        Returns:
            Analiz sonucu
        """
        import time
        start_time = time.time()
        
        logger.info(f"üöÄ Starting analysis: file={filename}, model={model}, reasoning={reasoning_level}")
        
        try:
            # 1. Dosyayƒ± √∂n i≈üle
            file_ext = os.path.splitext(filename)[1].lower()
            preprocessed = preprocess_drawing(file_bytes, file_ext, enhance_mode=enhance_mode)
            
            if preprocessed["status"] != "success" or not preprocessed.get("pages"):
                raise AnalysisError("Failed to preprocess drawing")
            
            # ƒ∞lk sayfayƒ± kullan (√ßoƒüu teknik resim tek sayfa)
            page_data = preprocessed["pages"][0]
            image_base64 = page_data["image_base64"]
            
            logger.info(f"‚úÖ Preprocessed: {page_data['width']}x{page_data['height']}px")
            
            # 2. Uygun modelle analiz et
            if model.startswith("gpt-"):
                result_dict = await self._analyze_with_openai(
                    image_base64, 
                    model, 
                    max_tokens,
                    reasoning_level
                )
            elif model.startswith("claude-"):
                result_dict = await self._analyze_with_claude(
                    image_base64,
                    model,
                    max_tokens
                )
            else:
                raise AnalysisError(f"Unsupported model: {model}")
            
            # 3. Metadata ekle
            processing_time = time.time() - start_time
            result_dict["metadata"] = AnalysisMetadata(
                model_used=model,
                processing_time=processing_time,
                confidence_score=result_dict.get("confidence_score", 0.8),
                tokens_used=result_dict.get("tokens_used"),
                warnings=result_dict.get("warnings", [])
            )
            
            # 4. Pydantic modeline √ßevir
            result = DrawingAnalysisResult(**result_dict)
            
            logger.info(f"‚úÖ Analysis complete in {processing_time:.1f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Analysis failed: {e}")
            raise AnalysisError(f"Analysis failed: {str(e)}")
    
    async def _analyze_with_openai(
        self,
        image_base64: str,
        model: str,
        max_tokens: int,
        reasoning_level: str
    ) -> Dict[str, Any]:
        """OpenAI GPT-5.2 / GPT-4 Vision ile analiz"""
        if not self.openai_client:
            raise AIKeyError("OpenAI API key not configured")
        
        logger.info(f"ü§ñ Analyzing with OpenAI {model} (reasoning: {reasoning_level})")
        
        try:
            # Prompt'u olu≈ütur
            system_prompt, user_prompt = get_analysis_prompt("openai", reasoning_level)
            
            # GPT-5.2 i√ßin Responses API kullan
            if model in ["gpt-5.2", "gpt-5.2-chat", "gpt-5", "gpt-5-chat"]:
                return await self._analyze_with_gpt52(
                    image_base64,
                    model,
                    system_prompt,
                    user_prompt,
                    max_tokens,
                    reasoning_level
                )
            
            # Eski modeller i√ßin Chat Completions API (geri uyumluluk)
            else:
                return await self._analyze_with_gpt4_legacy(
                    image_base64,
                    model,
                    system_prompt,
                    user_prompt,
                    max_tokens
                )
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Failed to parse OpenAI response as JSON: {e}")
            raise AnalysisError(f"Invalid JSON response from AI: {e}")
        except Exception as e:
            logger.error(f"‚ùå OpenAI API error: {e}")
            raise AnalysisError(f"OpenAI API error: {e}")
    
    async def _analyze_with_gpt52(
        self,
        image_base64: str,
        model: str,
        system_prompt: str,
        user_prompt: str,
        max_tokens: int,
        reasoning_level: str
    ) -> Dict[str, Any]:
        """
        GPT-5.2 Responses API ile analiz
        Yeni reasoning parametreleri kullanƒ±lƒ±r
        """
        logger.info(f"üöÄ Using GPT-5.2 Responses API (reasoning: {reasoning_level})")
        
        # Reasoning effort mapping
        effort_map = {
            "medium": "medium",
            "high": "high",
            "xhigh": "xhigh"
        }
        effort = effort_map.get(reasoning_level, "high")
        
        # Responses API √ßaƒürƒ±sƒ±
        response = self.openai_client.responses.create(
            model=model,
            input=[
                {"type": "text", "text": f"{system_prompt}\n\n{user_prompt}"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{image_base64}",
                        "detail": "high"
                    }
                }
            ],
            reasoning={"effort": effort},
            text={"verbosity": "high"},  # Detaylƒ± analiz istiyoruz
            max_output_tokens=max_tokens,
        )
        
        # Yanƒ±tƒ± parse et
        content = response.output_text
        result = json.loads(content)
        
        # Token bilgisi (varsa)
        if hasattr(response, 'usage'):
            result["tokens_used"] = response.usage.total_tokens
        
        logger.info(f"‚úÖ GPT-5.2 analysis complete. Tokens: {result.get('tokens_used')}")
        return result
    
    async def _analyze_with_gpt4_legacy(
        self,
        image_base64: str,
        model: str,
        system_prompt: str,
        user_prompt: str,
        max_tokens: int
    ) -> Dict[str, Any]:
        """
        GPT-4 Vision - Chat Completions API (geri uyumluluk)
        """
        logger.info(f"üìü Using legacy Chat Completions API for {model}")
        
        # API √ßaƒürƒ±sƒ±
        response = self.openai_client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_base64}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ],
            max_tokens=max_tokens,
            temperature=settings.temperature
        )
        
        # Yanƒ±tƒ± parse et
        content = response.choices[0].message.content
        
        # JSON parse et
        result = json.loads(content)
        result["tokens_used"] = response.usage.total_tokens if response.usage else None
        
        logger.info(f"‚úÖ GPT-4 legacy analysis complete. Tokens: {result.get('tokens_used')}")
        return result
    
    async def _analyze_with_claude(
        self,
        image_base64: str,
        model: str,
        max_tokens: int
    ) -> Dict[str, Any]:
        """Anthropic Claude ile analiz"""
        if not self.anthropic_client:
            raise AIKeyError("Anthropic API key not configured")
        
        logger.info(f"ü§ñ Analyzing with Claude {model}")
        
        try:
            # Prompt'u olu≈ütur
            system_prompt, user_prompt = get_analysis_prompt("claude", "high")
            
            # API √ßaƒürƒ±sƒ±
            response = self.anthropic_client.messages.create(
                model=model,
                max_tokens=max_tokens,
                temperature=settings.temperature,
                system=system_prompt,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/png",
                                    "data": image_base64
                                }
                            },
                            {
                                "type": "text",
                                "text": user_prompt
                            }
                        ]
                    }
                ]
            )
            
            # Yanƒ±tƒ± parse et
            content = response.content[0].text
            
            # JSON parse et
            result = json.loads(content)
            result["tokens_used"] = response.usage.input_tokens + response.usage.output_tokens if hasattr(response, 'usage') else None
            
            logger.info(f"‚úÖ Claude analysis complete. Tokens: {result.get('tokens_used')}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Failed to parse Claude response as JSON: {e}")
            raise AnalysisError(f"Invalid JSON response from AI: {e}")
        except Exception as e:
            logger.error(f"‚ùå Claude API error: {e}")
            raise AnalysisError(f"Claude API error: {e}")


# Singleton instance
analyzer = DrawingAnalyzer()
